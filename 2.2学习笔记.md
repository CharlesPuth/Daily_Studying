```python
"""
@author: ChangLiang
@contact: 1452380548cl@gmail.com
@time: 2021/2/2 0008 20:00
"""
```

## 1 对FCN中对称网络的进一步学习

### 1.1 上采样（Upsampling）、上池化（Unpooling）、反卷积（Deconvolution）

#### 1.上采样（Upsampling）

在FCN、U-net等网络结构中，我们见识到了上采样这个东西。那么，什么是上采样呢？简单来说：**上采样指的是任何可以让你的图像变成更高分辨率的技术**。最简单的方式是**重采样和插值**：将输入图片进行rescale到一个想要的尺寸，而且计算每个点的像素点，使用如***双线性插值***等插值方法对其余点进行插值来完成上采样过程。下图为upsampling对应Maxpooling的逆操作，可以看到是**直接进行同样的值的还原（可以理解为未保留最大值位置，直接进行值的重复）**。

<img src="C:\Users\14523\AppData\Roaming\Typora\typora-user-images\image-20210203154033854.png" alt="image-20210203154033854" style="zoom: 50%;" />

#### 2.上池化（Unpooling）

Unpooling是在CNN中常用的来表示max pooling的逆操作。简单来说，记住做max pooling的时候的最大item的位置，比如一个3x3的矩阵，max pooling的size为2x2，stride为1，**反卷积记住其位置，其余位置至为0**就行，如下所示：

<img src="C:\Users\14523\AppData\Roaming\Typora\typora-user-images\image-20210203154217388.png" alt="image-20210203154217388" style="zoom: 50%;" />

#### 3.反卷积（Deconvolution）

Deconvolution(反卷积)在CNN中常用于表示一种反向卷积 ，但它并不是一个符合严格数学定义的反卷积操作。与Unpooling不同，使用反卷积来对图像进行上采样是可以**习得的**。通常用来对卷积层的结果进行上采样，使其回到原始图片的分辨率。

反卷积也被称为**分数步长卷积**([convolution with fractional strides](https://arxiv.org/pdf/1605.06211v1.pdf))或者**转置卷积**([transpose convolution](https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#conv2d_transpose))或者**后向卷积**(backwards strided convolution)。目前最常用的为**转置卷积**。为了要让经过卷积的结果回到卷积前的模样。如图这个2x2的的结果，如何回到4x4呢？其实这种也算一种卷积的操作，只不过进行了padding操作，如下左图；通常大家会选择更大的dilation（等价于小于1的stride）来增强上采样的效果（可以理解成分数步长卷积，右下图显示的是stride=1/2）

<img src="C:\Users\14523\AppData\Roaming\Typora\typora-user-images\image-20210203160355619.png" alt="image-20210203160355619" style="zoom:50%;" /><img src="C:\Users\14523\AppData\Roaming\Typora\typora-user-images\image-20210203160306425.png" alt="image-20210203160306425" style="zoom: 33%;" />

#### 4.三者区别

Unsapling不必多说，直接将值进行复制扩充即可；UnPooling的过程，特点是在Maxpooling的时候保留最大值的位置信息，之后在unPooling阶段使用该信息扩充Feature Map，除最大值位置以外，其余补0。两者的区别在于UnSampling阶段没有使用MaxPooling时的位置信息，而是直接将内容复制来扩充Feature Map。从图中即可看到两者结果的不同。反卷积是卷积的逆过程，又称作转置卷积。

最大的区别在于**反卷积过程是有参数要进行学习的，因为卷积核中有权重（w）和偏置（b）的存在（类似卷积过程）**，**理论是反卷积可以实现UnPooling和unSampling，只要卷积核的参数设置的合理。**

目前已有一些可视化的文章来给出不同的操作得到的效果，如下所示：

**[图片引用文章：Learning Deconvolution Network for Semantic Segmentation    ]**

是一篇对FCN做了深层次分析的文章，尤其是对称反卷积网络，后期值得一看，就比如本文中对反卷积网络的分析：FCN只是在响应图(activation maps)中进行简单的反卷积(deconvolution)，而本文方法可获得稠密的像素级别的概率图．在这篇文章中中，低层的deconvolution层可获得目标的位置，形状等粗略信息．而高层的deconvolution层可获得更精细的信息．Unpooling层和deconvolution目的不同，unpooling层是通过回溯原始位置来获得更好的结构。可视化反卷积网络的每一层如下图

<img src="C:\Users\14523\AppData\Roaming\Typora\typora-user-images\image-20210203160907283.png" alt="image-20210203160907283" style="zoom: 67%;" />

图（a）是输入层；图（b）是1414反卷积的结果；图（c）是2828的UnPooling结果；图（d）是2828的反卷积结果；图（e）是5656的Unpooling结果；图（f）是5656反卷积的结果；图（g）是112112 UnPooling的结果；图（h）是112112的反卷积的结果；图（i）和图（j）分别是224224的UnPooling和反卷积的结果。两者各有特点。

## 2 从CNN到FCN：分割背景的最后介绍

### 2.1图像分割/语义分割：

什么是图像分割问题呢？ 简单的来讲就是给一张图像，检测是用框出框出物体，而图像分割分出一个物体的准确轮廓。也这样考虑，给出一张图像 Ｉ，这个问题就是求一个函数，从I映射到Mask。至于怎么求这个函数有多种方法。，自变量I是原图，因变量mask是分割结果.。进行像素级分类，mask=function(I)。

**语义分割**是计算机视觉中的基本任务之一，在语义分割中我们需要将视觉输入分为不同的语义可解释类别；不同于**目标检测**只是简单地将图片或视频中的目标区域用一个**矩形框标注出来**，语义分割将目标的检测精准到了**像素级别**，如图：

<img src="C:\Users\14523\AppData\Roaming\Typora\typora-user-images\image-20210203203023221.png" alt="image-20210203203023221" style="zoom:50%;" />

### 2.2FCN相对CNN的创新综述

• 卷积化：即将传统CNN结构（文中提到的Alexnet、VGG）**最后的全连接层改成卷积层**，以便进行直接分割，这是十分有创造性的。

• 上采样：由于网络过程中进行了一系列下采样，使得特征层大小减小，最后得到的预测层和原图一致，需要采用上采样，作用类似于**反卷积**。

• **并联跳跃结构**：想法类似于resnet和inception，在进行分类预测时**利用多层信息**，具体如下图：

<img src="C:\Users\14523\AppData\Roaming\Typora\typora-user-images\image-20210203165434709.png" alt="image-20210203165434709" style="zoom:50%;" />

FCN采取解决方法是将多个pool和特征map融合起来，由于不同层的pool、特征map大小尺寸是不一样的，所以融合应该前上采样到同一尺寸。**这里的融合是拼接在一起(concact)**，不是对应元素相加。

### 2.3 FCN(U-net)创新得到效果的根本原因：利用low-level和high-level特征的融合（即如上的并联跳跃结构）

在FCN论文中，作者采用了combine网络的low-level和high-level特征的方式。这是因为：

① **网络比较深的时候**，特征图通常比较小，对这种特征图进行上采样——有很好的语义信息，但分辨率很差。
② **网络比较浅的时候**，特征图通常比较大（接近input image），对这种特征图进行上采样——有很好的细节，但语义信息很差。

因此，对两者进行combine，我们可以在**得到很好的细节基础上，也能获得尽可能强的图像语义信息**。