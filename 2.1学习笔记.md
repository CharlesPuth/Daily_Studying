```python
"""
@author: ChangLiang
@contact: 1452380548cl@gmail.com
@time: 2021/2/1 0008 20:00
"""
```

## 1.从CNN到FCN（理论层面）

### 1.1背景知识：为何在医学图像使用FCN而放弃CNN

#### **CNN框架概述：**

基于CNN 的框架，就是对图像的每一个像素点进行分类，在每一个像素点上取一个patch，当做一幅图像，输入神经网络进行训练，这是一个二分类问题，把图像中所有label为0的点作为负样本，所有label为1的点作为正样本。（也即背景和所需要组织）。CNN的强大之处在于它的多层结构能自动学习特征，并且可以学习到多个层次的特征: 较浅的卷积层感知域较小，学习到一些局部区域的特征；较深的卷积层具有较大的感知域，能够学习到更加抽象一些的特征。

这种网络显然有两个缺点：1.**计算冗余、内存开销太大：**，由于每个像素点都需要取一个patch，那么相邻的两个像素点的patch相似度是非常高的，这就导致了非常多的计算冗余（反复进行卷积），导致网络训练很慢；2.**感受野大小只能提取局部特征使得分类性能受限制：**感受野和定位精度不可兼得，当感受野选取比较大的时候，后面对应的pooling层的降维倍数就会增大，这样就会导致定位精度降低（一大片区域内的很多个像素点被降为一个点），但是如果感受野比较小，那么分类精度就会降低（像素点太过离散，每个感受野内特征信息不足，导致出错率更高）。

#### **FCN框架概述：**

全卷积网络(FCN)则是从抽象的特征中恢复出每个像素所属的类别。即从图像级别的分类进一步延伸到像素级别的分类。较浅的高分辨率层用来解决像素定位的问题，较深的层用来解决像素分类的问题。采用反卷积层对最后一个卷积层的feature map进行上采样, 使它恢复到输入图像相同的尺寸，从而可以对每个像素都产生了一个预测, 同时保留了原始输入图像中的空间信息, 最后在上采样的特征图上进行逐像素分类。 

#### **CNN与FCN框架的区别联系：**

至今用于医学图像分割的只有CNN和FCN两种网络模型，并且大趋势是抛弃CNN使用FCN。

1.很明显的一个特点是FCN中**不包含全连接层（将其换成全卷积层）**了，这也很好去理解，因为CNN的分类输出是**输出一个向量**，里面的值代表着这幅图像到底是什么（归属哪一类的概率最高），经过全连接层处理之后就可以将之前处理过的图像转化为目标向量；但是FCN则是输入图像，**输出图像**。（如果输出图像还是用全连接层那参数就太太太多了）

2.不包含全连接层会导致一个好处：FCN可以接受**任意尺寸的输入图像**（因为全连接层的输入要求是个定值，这样层层向前推进，输入也就是固定的了）

3.FCN中国输出结果的每个值映射到输入图像上的感受野的窗口是固定的（最终的“1个”特征点对应着一片固定的区域），也就是检测窗口是固定的，导致检测效果没那么好，但是速度却得到了很大的提升，而且可以输入任意尺寸的图片，为目标检测提供了一种新思路。

## 2.FCN重点详解（理论泛解）

[本小节来源于知乎https://zhuanlan.zhihu.com/p/268205305     讲的十分透彻  侵删]

### 2.1FCN如何理解网络的输出？

#### **1.特征图尺寸变化**

我们首先不考虑通道数，来看一下上面网络中的特征图尺寸的具体变化，如下图，途中绿色为卷积核，蓝色为特征图：

<img src="https://pic3.zhimg.com/80/v2-9cc2766e812d23a24d58a7bbf84b277a_1440w.jpg" alt="img" style="zoom:50%;" />

从上图中，我们可以看到，输入是一个14x14大小的图片，经过一个5x5的卷积（不填充）后，得到一个10x10的特征图，然后再经过一个2x2的池化后，尺寸缩小到一半变成5x5的特征图，再经过一个5x5的卷积后，特征图变为1x1，接着后面再进行两次1x1的卷积（类似全连接操作），最终得到一个1x1的输出结果，那么该1x1的输出结果，就代表最前面14x14图像区域的分类情况，如果对应到上面的猫狗和背景的分类任务，那么最后输出的结果应该是一个1x3的矩阵，其中每个值代表14x14的输入图片中对应类别的分类得分。

#### **2.不同尺寸的输入图片**

好了，不是说可以接收任意尺寸的输入吗？我们接下来看一个大一点的图片输入进来，会得到什么样的结果，如下图：

<img src="https://pic2.zhimg.com/80/v2-9b31bf337601c58e4e26d213dc40fc69_1440w.jpg" alt="img" style="zoom:50%;" />

我们可以看到上面的图，输入尺寸有原来的14x14变成了16x16，那么经过一个5x5的卷积（不填充）后，得到一个12x12的特征图，然后再经过一个2x2的池化后，尺寸缩小到一半变成6x6的特征图，再经过一个5x5的卷积后，特征图变为2x2，接着后面再进行两次1x1的卷积（类似全连接操作），最终得到一个2x2的输出结果，那么该2x2的输出结果，就代表最前面16x16图像区域的分1类情况，然而，输出是2x2，怎么跟前面对应呢？哪一个像素对应哪个区域呢？我们看下图：

<img src="https://pic4.zhimg.com/80/v2-484d216f7b782d22a0ac8866bdac2fdb_1440w.jpg" alt="img" style="zoom:50%;" />

根据卷积池化反推，前面图3，我们知道，最后的输出1x1代表了前面14x14的输入的分类结果，那么我们根据卷积核的作用范围可以推出，上图中最后输出2x2中左上角的橙色输出就代表了16x16中的橙色区域（红色框），依次类推，输出2x2中右上角的蓝色输出就代表了16x16中的黄色框区域，输出2x2中左下角的蓝色输出就代表了16x16中的黑色框区域，输出2x2中右下角的蓝色输出就代表了16x16中的紫色框区域，其中每个框的大小都是14x14.也就是说输出的每个值代表了输入图像中的一个区域的分类情况。

#### **3.FCN是如何对目标检测进行加速的？**

根据上一副图，我们知道FCN最后的输出，每个值都对应到输入图像的一个检测区域，也就是说FCN的输出直接反应了对应输入图像检测区域的分类情况，由于图4和图5均没考虑通道情况，那么我们将网络放到一个正常的28x28x3的图像上，考虑上特征图的通道数，看下输出值的对应情况，如下图：

<img src="https://pic1.zhimg.com/80/v2-9286164a9e70f3f9b2474676b78e2208_1440w.jpg" alt="img" style="zoom: 67%;" />

上图中绿色区域表现了依次通过网络后的特征图尺寸变化情况。跟图5类似，因为这是一个猫狗和背景的三分类任务，所以最后输出的图像大小为8x8x3，以输出图像左上角绿色点为例，该点深度为3，对应输入图像的绿色区域，该点的3个值反应了输入图的绿色区域是分类为猫狗还是背景的得分情况。

总的来说，FCN利用了输出结果和输入图像的对应关系，直接给出了输入图像相应区域的分类情况，取消了传统目标检测中的滑动窗口选取候选框。

### Tips-CNN与FCN中一些重要的基础知识补充

#### 1.关于CNN与FCN中label的问题

（自己的理解）分类可以分很多类打很多的label，但是分割只需要在图中分出前景后景，打两个label。

#### 2.关于通道数的问题

CNN的卷积核通道数 = 卷积输入层的通道数（理解：输入图像多少通道，我们的特侦提取器也即卷积核就要对多少通道进行提取）    CNN的卷积输出层通道数 = 卷积核的个数（理解：我们所使用了几个特侦提取器，就会输出几个提取的特征量）

#### 3.关于1x1卷积的问题

1x1卷积的作用：

- 增加非线性

1x1的卷积核的卷积过程相当于全链接层的计算过程，并且还加入了非线性激活函数，从而可以增加网络的非线性，使得网络可以表达更加复杂的特征。

- 特征降维

通过控制卷积核的数量达到通道数大小的放缩。特征降维带来的好处是可以减少参数和减少计算量。假如前一层输入大小为28 x 28 x 192，引入1x1x16的卷积核，输出大小为28 x 28 x 16。减少了计算的同时也减少了参数。

#### 4.关于卷积方法的问题

##### 参数说明

**W**：矩阵宽，**H**：矩阵高，**F**：卷积核宽和高，**P**：**padding**（需要填充的**0**的个数），**N**：卷积核的个数，**S**：步长

卷积运算可划分为三种：Same卷积、Valid卷积、Full卷积(反卷积)。

##### 4.1 Same卷积（Pad）

​    通过Padding（**即在输入图像边缘补充像素点来抵抗卷积导致的图像变小**）填充0运算保证卷积前后特征图大小不变，即W1=W2、H1=H2。公式为：(W1-F+2P)/S+1 = W2

若令W1=W2则可计算填充0的P的值为多少。如，令F=3，S=1，W1=5，则计算P=1.

<img src="https://img-blog.csdnimg.cn/20181202092350765.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2F0dGl0dWRlX3l1,size_16,color_FFFFFF,t_70" alt="img" style="zoom: 33%;" />

##### 4.2 Valid卷积（最传统）

  不加入Padding运算，直接进行卷积运算，特征图会变小。公式为：(W1-F)/S+1=W2

  如，令W1=5，F=3，S=1，则W2=3

<img src="https://img-blog.csdnimg.cn/20181202092350578.png" alt="img" style="zoom: 50%;" />

##### 4.3 Full卷积（反卷积）

   实现反卷积运算的核心步骤是在特征图中padding 0，然后进行卷积运算使得特征图变大。（**即先人为在特征图像边缘补充像素点来使得图像变大，纵使卷积了会变小一点总体也是变大的**）

公式为：(W1-F+2P)/S+1 = W2

   如，令W1=5，F=3，P=2，S=1，则W2=7

<img src="https://img-blog.csdnimg.cn/20181202092350590.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2F0dGl0dWRlX3l1,size_16,color_FFFFFF,t_70" alt="img" style="zoom:50%;" />

  虽然在卷积图中padding0，但是反卷积后的

##### 4.4 FCN反卷积（FCN提出的时候的特殊定义）

​    而本文使用的反卷积运算方式则不同于以上的Full卷积方式，而是首先对特征图各神经元之间进行0填充，即上池化；然后再进行卷积运算。计算公式为：(W1−1)×S-2×P+F=W2

<img src="https://img-blog.csdnimg.cn/20181202092350855.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2F0dGl0dWRlX3l1,size_16,color_FFFFFF,t_70" alt="img" style="zoom:33%;" />

​    如，令W1=3，S=2，P=1，F=3，则W2=5

#### 5.图像的上采样（upsampling）与下采样（subsampled）：主要介绍上采样

经过多次卷积和pooling以后，得到的图像越来越小，分辨率越来越低。其中图像到图片是最小的一层时，所产生图叫做heatmap热图，热图就是我们最重要的高维特征图，得到高维特征的heatmap之后就是最重要的一步也是最后的一步对原图像进行upsampling，把图像进行放大、放大、放大，到原图像的大小。这一技巧在实践中经常使用，一次来获得更好的结果。比如，通常将一张图像尺寸变得更大，然后使用变换后的卷积神经网络来对空间上很多不同位置进行评价得到分类评分，然后在求这些分值的平均值。

**代码中会直接出现 upsampling 的方法**